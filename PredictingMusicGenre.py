# -*- coding: utf-8 -*-
"""ProyectoINF354.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I-uC4r0OorReq3CVlANQa_ctm-8V_7WA

###IMPORTACION DE LIBRERIAS
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder, LabelEncoder, KBinsDiscretizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

import io
import requests

"""###LECTURA DEL DATASET DESDE GITHUB"""

url = 'https://raw.githubusercontent.com/joelAnara/ExamenFinal/refs/heads/main/DATASET/Music%20Info.csv'
music = requests.get(url).content
music = pd.read_csv(io.StringIO(music.decode('utf-8')))

music

music.info()

"""###LIMPIAR DATOS"""

music.shape

len(music["track_id"].unique())

len(music["artist"].unique())

music["key"].unique()

music["mode"].unique()

music["genre"].unique()

music["genre"].value_counts(dropna=False)

"""Se eliminan nulos de la clase"""

music = music.dropna(subset=['genre'])

artists = music["artist"].value_counts()[:20].sort_values(ascending = False)

artists

plt.barh(artists.index, artists)
plt.xlabel("Number of songs per artist")
plt.title("Songs per artist")
plt.show()

music.info()

"""Se eliminan carasteristicas(columnas)"""

music.drop(columns = ["track_id", "name", "artist","spotify_preview_url","spotify_id","tags","time_signature"], inplace = True)

music

for i in music.index:
    if 'Rock' in str(music.loc[i, 'genre']):
        music.loc[i, 'genre'] = 'Rock'
    else:
        music.loc[i, 'genre'] = 'No Rock'

music

"""###ANALISIS DE DATOS"""

#popularity liveness key and mode number instead of letters
#year time_signature
def plot_counts(feature, order = None):
    sns.countplot(x = feature, data = music, palette = "ocean", order = order)
    plt.title(f"Counts in each {feature}")
    plt.show()

#plot_counts("key", ["A", "A#", "B", "C", "C#", "D", "D#", "E", "F", "F#", "G", "G#"])
plot_counts("key", ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"])

music["key"].value_counts()

plot_counts("mode")

plt.figure(figsize = (9, 4))
plot_counts("genre")

music["tempo"] = music["tempo"].astype("float")

music["tempo"] = np.around(music["tempo"], decimals = 2)

music.info()

numeric_features = music.drop(["genre"], axis = 1)

fig, axs = plt.subplots(ncols = 3, nrows = 5, figsize = (15, 15))
index = 0

axs = axs.flatten()
for k, v in numeric_features.items():
    sns.histplot(v, ax = axs[index])
    index += 1
plt.tight_layout(pad = 0.4, w_pad = 0.5, h_pad = 5.0)

fig, axs = plt.subplots(ncols = 3, nrows = 5, figsize = (15, 15))
idx = 0
axs = axs.flatten()
for k, v in numeric_features.items():
    sns.boxplot(y = k, data = numeric_features, ax = axs[idx])
    idx += 1
plt.tight_layout(pad = 0.4, w_pad = 0.5, h_pad = 5.0)

"""###PREPROCESAMIENTO"""

def handle_outliers(df, column_name, method='remove'):
    Q1 = df[column_name].quantile(0.25)
    Q3 = df[column_name].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    print(lower_bound, upper_bound)
    if method == 'remove':
        return df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]
    elif method == 'cap':
        df[column_name] = df[column_name].clip(lower=lower_bound, upper=upper_bound)
        return df
    elif method == 'impute':
        median_value = df[column_name].median()
        df.loc[(df[column_name] < lower_bound) | (df[column_name] > upper_bound), column_name] = median_value
        return df

music.info()

music = handle_outliers(music, "year", method = "cap")

music = handle_outliers(music, "duration_ms", method = "cap")

music = handle_outliers(music, "loudness", method = "cap")

music = handle_outliers(music, "speechiness", method = "cap")

music = handle_outliers(music, "acousticness", method = "cap")

music = handle_outliers(music, "liveness", method = "cap")

# Ver las clases de 'genre' (géneros musicales)
print(music['genre'].value_counts())

# Dividir el dataset en dos partes: una por cada género musical
# Usamos "genre" como columna con géneros musicales
genre_counts = music['genre'].value_counts()

# Encontrar el género musical con el mayor número de muestras
max_samples = genre_counts.max()

# Crear un DataFrame vacío para las clases balanceadas
balanced_music = pd.DataFrame()

# Para cada género musical, realizar sobremuestreo
for genre in genre_counts.index:
    genre_class = music[music['genre'] == genre]

    # Sobremuestreo para igualar la clase minoritaria a la mayoritaria
    genre_class_upsampled = resample(genre_class,
                                     replace=True,  # con reemplazo
                                     n_samples=max_samples,  # igualar tamaño al máximo
                                     random_state=42)

    # Concatenar la clase sobremuestreada
    balanced_music = pd.concat([balanced_music, genre_class_upsampled])

balanced_music['genre'].value_counts()

"""La fórmula para generar una muestra sintética en SMOTE es:

$$
x_{syn} = x_i + \lambda \cdot (x_{i}^{(j)} - x_i)
$$
"""

# Ver la distribución de géneros musicales
print(music['genre'].value_counts())

# Separar las características (X) y la variable objetivo (y)
X = music.drop('genre', axis=1)
y = music['genre']

# Aplicar SMOTE para generar muestras sintéticas
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Verificar el nuevo balance de clases
print(pd.Series(y_resampled).value_counts())

# Crear un DataFrame con el dataset balanceado
balanced_music = pd.DataFrame(X_resampled, columns=X.columns)
balanced_music['genre'] = y_resampled

music=balanced_music

music_features = music.drop("genre", axis = 1)
music_labels = music["genre"]

#Estandarizacion (0-1)
scaler = StandardScaler()
music_features_scaled = scaler.fit_transform(music_features)

music_features_scaled.mean(), music_features_scaled.std()

music.to_csv('music.csv', index=False)

music_features_scaled

"""###CLASIFICADOR RANDOM FOREST

La **esperanza** de la predicción de Random Forest es:

$$
\mathbb{E}[f(x)] = \frac{1}{M} \sum_{m=1}^{M} \mathbb{E}[f_m(x)]
$$

La **varianza** de la predicción de Random Forest se puede calcular como:

$$
\text{Var}(f(x)) = \frac{1}{M^2} \sum_{m=1}^{M} \text{Var}(f_m(x))
$$
"""

train_features, test_features, train_labels, test_labels = train_test_split(
    music_features_scaled, music_labels, test_size=0.2, stratify=music_labels)

train_features.shape, train_labels.shape, test_features.shape,test_labels.shape

model = RandomForestClassifier(n_estimators = 10, max_depth = 5, min_samples_leaf = 1)

model.fit(train_features, train_labels)

def classification_task(estimator, features, labels):

    predictions = estimator.predict(features)

    print(f"Accuracy: {accuracy_score(labels, predictions)}")

classification_task(model, train_features, train_labels)

classification_task(model, test_features, test_labels)

print(classification_report(test_labels, model.predict(test_features)))

plt.figure(figsize = (8, 6))
sns.heatmap(confusion_matrix(test_labels, model.predict(test_features)),
    annot = True,
    fmt = ".0f",
    cmap = "vlag",
    linewidths = 2,
    linecolor = "red",
    xticklabels = model.classes_,
    yticklabels = model.classes_)
plt.title("Actual values")
plt.ylabel("Predicted values")
plt.tight_layout()
plt.show()

model.feature_importances_

"""###PREPROCESAMIENTO VISUALIZACION"""

print("------------COLUMNAS Y TIPOS DE DATOS------------")
music.info()

print("------------LABELENCODER------------")
clase = music["genre"]
preprocesamiento = LabelEncoder()
LABELENCODER = preprocesamiento.fit_transform(clase)
df_encoded = pd.DataFrame({
    'Clase Original': clase,
    'Clase Codificada': LABELENCODER
})

df_encoded_unique = df_encoded.drop_duplicates()
df_encoded_unique

print("------------ONEHOTENCODER------------")

preprocesamiento = OneHotEncoder(sparse_output=False)
resultado5 = preprocesamiento.fit(music[["genre"]])
Generos_Musicales = preprocesamiento.transform(music[["genre"]])

df_generos = pd.DataFrame(Generos_Musicales, columns=preprocesamiento.categories_)

df_generos

print("------DISCRETIZACION-----")

# Eliminar la columna 'genre' y obtener las demás columnas
columnas_a_discretizar = music.drop(columns=['genre'])
df_discretizado = columnas_a_discretizar.copy()

discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')

# Iterar sobre las columnas restantes y aplicar la discretización
for columna in df_discretizado.columns:
    if df_discretizado[columna].nunique() > 1:  # Verificar que la columna tenga más de un valor único
        df_discretizado[columna] = discretizer.fit_transform(df_discretizado[columna].values.reshape(-1, 1)).flatten()
    else:
        print(f"Columna {columna} es constante y no se discretiza.")
df_discretizado['genre'] = music['genre']
df_discretizado

"""###CLASIFICADOR(ARBOLES DE DESICION)"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Separar características y etiquetas
X = df_discretizado.drop(columns=['genre'])
y = df_discretizado['genre']  # Etiqueta para clasificación

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Crear el modelo de Árbol de Decisión
dt_model = DecisionTreeClassifier(max_depth=8, min_samples_leaf=5, random_state=42)

# Entrenar el modelo
dt_model.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred = dt_model.predict(X_test)

# Evaluar el desempeño del modelo
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)

# Imprimir resultados
print("Accuracy del modelo de Árbol de Decisión: {:.2f}%".format(accuracy * 100))
print("\nReporte de clasificación:\n", report)

# Convertir la matriz de confusión a DataFrame para mostrar nombres de filas y columnas
conf_matrix_df = pd.DataFrame(conf_matrix, index=y_test.unique(), columns=y_test.unique())
print("\nMatriz de confusión:\n", conf_matrix_df)

# Visualizar la matriz de confusión con seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=y_test.unique(), yticklabels=y_test.unique())
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.show()

"""###SPLIT(100 ASIGNACIONES)"""

# Inicializar el modelo de RandomForest
model100 = RandomForestClassifier(n_estimators=10, max_depth=5, min_samples_leaf=1)

# Definir la cantidad de repeticiones para el split
n_splits = 100

# Crear una lista para almacenar las precisiones de cada split
accuracies = []

# Realizar el split 100 veces
for i in range(n_splits):
    # Realizar un split 80-20
    X_train, X_test, y_train, y_test = train_test_split(music_features_scaled, music_labels, test_size=0.2, random_state=i)

    # Ajustar el modelo al conjunto de entrenamiento
    model100.fit(X_train, y_train)

    # Hacer predicciones sobre el conjunto de test
    y_pred = model100.predict(X_test)

    # Calcular la precisión y agregarla a la lista
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)

# Calcular la mediana de las precisiones
median_accuracy = np.median(accuracies)

# Mostrar el resultado
print(f"La mediana de la precisión después de 100 splits es: {median_accuracy}")

# Inicializar el modelo de RandomForest
model100 = RandomForestClassifier(n_estimators=10, max_depth=5, min_samples_leaf=1)

# Definir la cantidad de repeticiones para el split
n_splits = 100

# Crear una lista para almacenar las precisiones de cada split
accuracies = []

# Realizar el split 100 veces
for i in range(n_splits):
    # Realizar un split 80-20
    X_train, X_test, y_train, y_test = train_test_split(music_features_scaled, music_labels, test_size=0.5, random_state=i)

    # Ajustar el modelo al conjunto de entrenamiento
    model100.fit(X_train, y_train)

    # Hacer predicciones sobre el conjunto de test
    y_pred = model100.predict(X_test)

    # Calcular la precisión y agregarla a la lista
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)

# Calcular la mediana de las precisiones
median_accuracy = np.median(accuracies)

# Mostrar el resultado
print(f"La mediana de la precisión después de 100 splits es: {median_accuracy}")

"""###Analisis Componentes Principales (PCA)"""

x_std = music_features_scaled
y = music_labels

x_std.shape

y.shape

cov_matrix = np.cov(x_std.T)
print("cov_matrix shape:",cov_matrix.shape)
print("Covariance_matrix",cov_matrix)

eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
print('Eigen Vectors \n%s', eigenvectors)
print('\n Eigen Values \n%s', eigenvalues)

# creamon un conjunto de pares (valores propios, vectores propios):
eig_pairs = [(eigenvalues[index], eigenvectors[:,index]) for index in range(len(eigenvalues))]

# ordenamos los pares (valor propio, vector propio) de mayor a menor con respecto al valor propio
eig_pairs.sort()

eig_pairs.reverse()
print(eig_pairs)

# separamos los valores propios y los vectores propios ordenados de forma descendente
eigvalues_sorted = [eig_pairs[index][0] for index in range(len(eigenvalues))]
eigvectors_sorted = [eig_pairs[index][1] for index in range(len(eigenvalues))]

print('Valores propios en orden descendente: \n%s' %eigvalues_sorted)

total = sum(eigenvalues)

# creamos una matriz de varianza explicada por cada vector propio... habrá 13 entradas ya que hay 13 vectores propios
var_explained = [(i / total) for i in sorted(eigenvalues, reverse=True)]
# una matriz de varianza acumulada. Habrá 13 entradas con 13 entradas acumuladas alcanzando casi el 100%
cum_var_exp = np.cumsum(var_explained)


plt.bar(range(1,14), var_explained, alpha=0.5, align='center', label='varianza individual explicada')
plt.step(range(1,14),cum_var_exp, where= 'mid', label='varianza acumulada explicada')
plt.ylabel('Relación de varianza explicada')
plt.xlabel('Componentes principales')
plt.legend(loc = 'best')
plt.show()

P_reduce = np.array(eigvectors_sorted[0:12])   # Reducimos las dimensiones

X_std_12D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca12 = pd.DataFrame(X_std_12D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:11])   # Reducimos las dimensiones

X_std_11D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca11 = pd.DataFrame(X_std_11D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:10])   # Reducimos las dimensiones

X_std_10D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca10 = pd.DataFrame(X_std_10D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:9])   # Reducimos las dimensiones

X_std_9D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca9 = pd.DataFrame(X_std_9D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:5])   # Reducimos las dimensiones

X_std_5D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca5 = pd.DataFrame(X_std_5D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:3])   # Reducimos las dimensiones

X_std_3D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca3 = pd.DataFrame(X_std_3D)  # convertimos los datos a un dataframe

P_reduce = np.array(eigvectors_sorted[0:2])   # Reducimos las dimensiones

X_std_2D = np.dot(x_std,P_reduce.T)   # proyección de datos originales en dimensiones de componentes principales

reduced_pca2 = pd.DataFrame(X_std_2D)  # convertimos los datos a un dataframe

# Datos originales
orig_x_train, orig_x_test, orig_y_train, orig_y_test = train_test_split(x_std, y, test_size=0.20, random_state=1)

#Datos reducidos con PCA
pca_x_train12, pca_x_test12, pca_y_train12, pca_y_test12 = train_test_split(reduced_pca12, y, test_size=0.20, random_state=1)
pca_x_train11, pca_x_test11, pca_y_train11, pca_y_test11 = train_test_split(reduced_pca11, y, test_size=0.20, random_state=1)
pca_x_train10, pca_x_test10, pca_y_train10, pca_y_test10 = train_test_split(reduced_pca10, y, test_size=0.20, random_state=1)
pca_x_train9, pca_x_test9, pca_y_train9, pca_y_test9 = train_test_split(reduced_pca9, y, test_size=0.20, random_state=1)
pca_x_train5, pca_x_test5, pca_y_train5, pca_y_test5 = train_test_split(reduced_pca5, y, test_size=0.20, random_state=1)
pca_x_train3, pca_x_test3, pca_y_train3, pca_y_test3 = train_test_split(reduced_pca3, y, test_size=0.20, random_state=1)
pca_x_train2, pca_x_test2, pca_y_train2, pca_y_test2 = train_test_split(reduced_pca2, y, test_size=0.20, random_state=1)

model_RandomForest = RandomForestClassifier(n_estimators = 10, max_depth = 5, min_samples_leaf = 1)
model_RandomForest.fit(orig_x_train, orig_y_train)

orig_y_predict = model_RandomForest.predict(orig_x_test)

pca_model = RandomForestClassifier(n_estimators = 10, max_depth = 5, min_samples_leaf = 1)
pca_model.fit(pca_x_train12, pca_y_train12)
pca_y_predict12 = pca_model.predict(pca_x_test12)
pca_model.fit(pca_x_train11, pca_y_train11)
pca_y_predict11 = pca_model.predict(pca_x_test11)
pca_model.fit(pca_x_train10, pca_y_train10)
pca_y_predict10 = pca_model.predict(pca_x_test10)
pca_model.fit(pca_x_train9, pca_y_train9)
pca_y_predict9 = pca_model.predict(pca_x_test9)
pca_model.fit(pca_x_train5, pca_y_train5)
pca_y_predict5 = pca_model.predict(pca_x_test5)
pca_model.fit(pca_x_train3, pca_y_train3)
pca_y_predict3 = pca_model.predict(pca_x_test3)
pca_model.fit(pca_x_train2, pca_y_train2)
pca_y_predict2 = pca_model.predict(pca_x_test2)

# mostrar puntuación de precisión de ambos modelos

print("Antes de PCA en la dimensión 13 original",accuracy_score(orig_y_test, orig_y_predict))
print("Después de PCA (en 12 dimensiones)",accuracy_score(pca_y_test12, pca_y_predict12))
print("Después de PCA (en 11 dimensiones)",accuracy_score(pca_y_test11, pca_y_predict11))
print("Después de PCA (en 10 dimensiones)",accuracy_score(pca_y_test10, pca_y_predict10))
print("Después de PCA (en 9 dimensiones)",accuracy_score(pca_y_test9, pca_y_predict9))
print("Después de PCA (en 5 dimensiones)",accuracy_score(pca_y_test5, pca_y_predict5))
print("Después de PCA (en 3 dimensiones)",accuracy_score(pca_y_test3, pca_y_predict3))
print("Después de PCA (en 2 dimensiones)",accuracy_score(pca_y_test2, pca_y_predict2))

"""###Aprendizaje No Supervisado(K-Means)"""

inertia = []
for k in range(1, 11):  # Probar k entre 1 y 10
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(music_features_scaled)
    inertia.append(kmeans.inertia_)

plt.plot(range(1, 11), inertia)
plt.title("Método del Codo")
plt.xlabel("Número de clusters")
plt.ylabel("Inercia")
plt.show()

# Establecer el número de clusters (k)
k = 2
kmeans = KMeans(n_clusters=k, random_state=42)

# Ajustar el modelo
clusters = kmeans.fit_predict(music_features_scaled)
music_K = music_features_scaled.copy()
# Convert music_K to a DataFrame if it's not already
music_K = pd.DataFrame(music_K)
# Añadir los clusters al DataFrame original
music_K['Cluster'] = clusters

reduced_pca2

# Visualizar los resultados
plt.scatter(reduced_pca2.iloc[:, 0], reduced_pca2.iloc[:, 1], c=music_K['Cluster'])
plt.title("Clustering con K-means")
plt.xlabel("Componente principal 1")
plt.ylabel("Componente principal 2")
plt.show()

"""###Algoritmo de la N-reina"""

!pip install mlrose-hiive
!pip install joblib==1.2.0

### Importamos las librerías necesarias
import mlrose_hiive as mlrose

import numpy as np

def queens_max(posicion):
    reina_no_ataca = 0
    for i in range(len(posicion) - 1):
        sin_ataque_j = 0
        for j in range(i + 1, len(posicion)):
            if (posicion[j] != posicion[i]) and (posicion[j] != posicion[i] + (j - i)) and (posicion[j] != posicion[i] - (j - i)):
                sin_ataque_j += 1
        if sin_ataque_j == len(posicion) - 1 - i:
            reina_no_ataca += 1
    if reina_no_ataca == len(posicion) - 1:
        reina_no_ataca += 1
    return reina_no_ataca

# Definir el número de reinas
N = 4  # Puedes cambiar este valor para N reinas

# Asignamos la función objetivo antes definida
objetivo = mlrose.CustomFitness(queens_max)

# Crear el problema de optimización
problema = mlrose.DiscreteOpt(length=N, fitness_fn=objetivo, maximize=True, max_val=N)

# Definir la programación de decaimiento (exp decay)
T = mlrose.ExpDecay()

# Definir el estado inicial (todas las reinas en la posición 0)
posicion_inicial = np.zeros(N, dtype=int)

## Resolver el problema usando recocido simulado
mejor_posicion, mejor_objetivo, _ = mlrose.simulated_annealing(problem=problema, schedule=T,
                                                              max_attempts=1000, max_iters=10000,
                                                              init_state=posicion_inicial)

# Mostrar los resultados
print(f'La mejor posición encontrada es: {mejor_posicion}')
print(f'El número de reinas sin atacarse en esta posición es: {mejor_objetivo}')

def graficar_tablero(posicion):
    N = len(posicion)
    tablero = np.zeros((N, N))  # Crear un tablero vacío
    for i in range(N):
        tablero[posicion[i], i] = 1  # Coloca un 1 donde hay una reina

    plt.figure(figsize=(6, 6))
    # Invertir el eje Y para que las filas se numeren desde abajo hacia arriba
    plt.imshow(tablero[::-1], cmap="binary", origin="upper")
    plt.xticks(range(N), labels=[str(i) for i in range(N)])
    plt.yticks(range(N), labels=[str(N-1-i) for i in range(N)])  # Ajustar las etiquetas de filas
    plt.title("Tablero de N-Reinas")
    plt.xlabel("Columnas")
    plt.ylabel("Filas")

    # Agregar marcas para las reinas
    for i in range(N):
        plt.text(i, N-1-posicion[i], '♛', ha='center', va='center', fontsize=18, color='red')

    plt.grid(False)
    plt.show()

# Ejemplo de uso
posicion = mejor_posicion  # Solución para el problema de 4 reinas
graficar_tablero(posicion)